
Expanded DistilBERT Benchmarking Project Plan
=============================================

1. Executive Summary
--------------------
Objective           : Build a fully-automated, repeatable benchmark that compares DistilBERT sequence-classification inference on CPU vs. GPU inside the university HPC cluster (AMD Milan + NVIDIA A100).
Key metrics         : Latency (ms/batch & throughput), peak memory (CPU RSS / GPU allocated), energy per sample (J or Wh).
Success             : A single `make benchmark` (locally) or `sbatch bench_distilbert.slurm` (cluster) runs end-to-end and produces: `results-<timestamp>.json`, four PNG plots, a 10-page PDF report, and a 12-slide deck.

2. Workâ€‘Breakdown Structure (WBS)
---------------------------------
Legend: ğŸ’» = code, ğŸ§ª = test, âš™ï¸ = CI, ğŸ“„ = docs, ğŸ”„ = refactor window

Phase 0 â€“ Governance & Preparation
  0.1 Draft Project Charter & repository README ............... ğŸ“„
      Deliverable: README.md with scope, goals, cluster spec, dataset licence
  0.2 Create repo, enable branch protection, project board .... ğŸ”„

Phase 1 â€“ Environment & Toolchain
  1.1 Conda env `distilbert_bench` (Python 3.10) .............. ğŸ’»ğŸ§ª
      Test: pytest tests/test_env.py passes (imports all libs)
  1.2 IDE: create Cursor project, add .gitignore, .cursorules . ğŸ’»
  1.3 CI pipeline (GitHub Actions) ............................ âš™ï¸

Phase 2 â€“ Data & Tokenization
  2.1 fetch_sst2.py downloads validation split ................ ğŸ’»ğŸ§ª
      Test: record count, MD5 hash stored
  2.2 tokenize.py exposing prepare_inputs() ................... ğŸ’»ğŸ§ª
  2.3 Dataâ€‘contract test (nightly CI cron) .................... âš™ï¸

Phase 3 â€“ Model Loader & Smoke Passes
  3.1 model.py load_model(device) ............................. ğŸ’»ğŸ§ª
  3.2 CUDA warmâ€‘up util ....................................... ğŸ’»

Phase 4 â€“ Benchmarking Harness
  4.1 latency.py (CPU/GPU timers) ............................. ğŸ’»ğŸ§ª
  4.2 memory.py (psutil / pynvml) ............................. ğŸ’»ğŸ§ª
  4.3 energy.py (pyRAPL & NVML) ............................... ğŸ’»ğŸ§ª
  4.4 runner.py loops over devices Ã— batch_sizes .............. ğŸ’»ğŸ§ª

Phase 5 â€“ HPC Integration
  5.1 bench_distilbert.slurm template ........................ ğŸ’»ğŸ§ª
  5.2 Cluster dryâ€‘run, JSON retrieval ......................... ğŸ’»ğŸ§ª

Phase 6 â€“ Continuous Refactoring & Logging (parallel)
  â€¢ Structured logging (loguru) .............. JSON log per run
  â€¢ Autoâ€‘formatter (ruff + black) preâ€‘commit .. PR fails on style
  â€¢ Refactor windows .......................... test coverage â‰¥ 90â€¯%
  â€¢ Codeâ€‘climate complexity reports (optional) .................

Phase 7 â€“ Analysis & Visualisation
  7.1 analysis.py load JSON â†’ pandas ......................... ğŸ’»ğŸ§ª
  7.2 Plot scripts produce 4 PNGs ............................ ğŸ’»ğŸ§ª
  7.3 insights.md autoâ€‘generated (jinja2) .................... ğŸ’»ğŸ§ª

Phase 8 â€“ Reporting & Artefacts
  8.1 report.md â†’ PDF via Pandoc ............................. ğŸ“„
  8.2 slides/distilbert_bench.pptx (12 slides) ............... ğŸ“„
  8.3 Release assets + SHA256 manifest ....................... ğŸ”„

3. Testing Strategy
-------------------
Level       Purpose                                 Tools
Unit        Validate pure functions                 pytest, pytestâ€‘benchmark
Integration Tokenization â†’ Model â†’ Metrics          tests/integration
System      SLURM job produces valid JSON           Goldenâ€‘file comparison
Smoke       5â€‘sample endâ€‘toâ€‘end run on laptop       make smoke
Regression  CI matrix (Py3.10/3.11, CUDA 11.8/12.1) GitHub Actions

4. Risk Register
----------------
ID  Risk                               Likelihood  Impact  Mitigation
R1  Cluster queue delays               Medium      High    Reserve GPU quota early; run CPU benchmarks first
R2  Energy sensors unavailable         Low         Medium  Preâ€‘check NVML privileges; fallback estimate
R3  Library updates break repro        Medium      Medium  Pin versions, archive wheelhouse
R4  Data licence conflict              Low         High    GLUE MIT licence; cite source


5. Cursorâ€‘Specific Configuration
--------------------------------
.cursorules
  - write tests first, then code
  - run pytest automatically
  - keep answers concise
  - suggest alternatives
  - avoid unnecessary explanations
  - prioritize technical detail
  - log every file change to logs/cursor_edits.log

rules.mdc
  ## Macro Prompts
  1. chain_of_thought: Explain your reasoning before coding.
  2. diagnose: Generate a diagnostic report of current repo state.

7. Deliverables Checklist
-------------------------
[ ] environment.yml + requirements.txt
[ ] src/ fully typed (mypy --strict)
[ ] tests/ â‰¥â€¯90â€¯% coverage
[ ] cluster/bench_distilbert.slurm
[ ] results/*.json, figures/*.png
[ ] report.pdf (â‰¤â€¯15â€¯pages) + slides.pptx
[ ] CHANGELOG.md and Git tag v1.0.0
